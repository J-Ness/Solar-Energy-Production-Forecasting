{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Name**\n",
    "\n",
    "[146] hey girl lets ML n chill\n",
    "\n",
    "**Member, StudNr**\n",
    "\n",
    "Sinan Maric, 529195\n",
    "\n",
    "Joakim Ness, 544839\n",
    "\n",
    "Ole Lasson, 543928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "train_b = pd.read_parquet('B/train_targets.parquet')\n",
    "train_c = pd.read_parquet('C/train_targets.parquet')\n",
    "\n",
    "raw_b = train_b\n",
    "\n",
    "X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "X_train_estimated_b = pd.read_parquet('B/X_train_estimated.parquet')\n",
    "X_train_estimated_c = pd.read_parquet('C/X_train_estimated.parquet')\n",
    "\n",
    "X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')\n",
    "\n",
    "X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "X_test_estimated_b = pd.read_parquet('B/X_test_estimated.parquet')\n",
    "X_test_estimated_c = pd.read_parquet('C/X_test_estimated.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_X(df):\n",
    "    data = df.copy()\n",
    "    if 'date_calc' in data.columns:\n",
    "        data.drop('date_calc', axis=1, inplace=True)\n",
    "\n",
    "    if 'date_forecast' in data.columns:\n",
    "        data.set_index('date_forecast', inplace=True)\n",
    "\n",
    "    \n",
    "    data = data.groupby(pd.Grouper(freq='1H')).mean()\n",
    "    \n",
    "    \n",
    "    data.dropna(how='all', inplace=True)\n",
    "    \n",
    "    data['hour'] = data.index.hour\n",
    "    data['week'] = pd.to_numeric(data.index.isocalendar().week)\n",
    "    data['week_hour'] = data['week'] * 100 + data['hour']\n",
    "    data['month'] = data.index.month\n",
    "\n",
    "\n",
    "    data['hour_sinus'] = np.sin(2*np.pi*data['hour']/ 23)\n",
    "    data['hour_cosine'] = np.cos(2*np.pi*data['hour'] / 23)\n",
    "\n",
    "    data['month_sinus'] = np.sin(2*np.pi*data['month'] / 12)\n",
    "    data['month_cosine'] = np.cos(2*np.pi*data['month'] / 12)\n",
    "\n",
    "    \n",
    "\n",
    "    data.drop(columns=['snow_density:kgm3', 'month', 'hour', 'week','week_hour'], inplace=True)\n",
    "    \n",
    "    data.rename_axis('time', inplace=True)\n",
    "\n",
    "    mapping = elevation_mapping = {\n",
    "            6.0 : 'A',\n",
    "            7.0 : 'B',\n",
    "            24.0 : 'C'\n",
    "        }\n",
    "    \n",
    "    data['location'] = data['elevation:m'].map(mapping)\n",
    "    data['location'] = data['location'].astype(str)\n",
    "    data.drop(columns=['elevation:m'], inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def remove_constants_Y(df):\n",
    "    data = df.copy()\n",
    "\n",
    "    # Create a mask to identify sequences of 3 or more consecutive rows with the same 'pv_measurement' (non-zero)\n",
    "    consecutive_mask = (data['pv_measurement'] == data['pv_measurement'].shift(1)) & (data['pv_measurement'] != 0)\n",
    "    consecutive_count = consecutive_mask.groupby((~consecutive_mask).cumsum()).cumsum()\n",
    "    mask_consecutive = (consecutive_count <= 3) | (~consecutive_mask)\n",
    "\n",
    "    #create a mask to identify sequences of 24 or more consecutive 0-valued pv-measurement\n",
    "    consecutive_mask_0 = (data['pv_measurement'] == data['pv_measurement'].shift(1)) & (data['pv_measurement'] == 0)\n",
    "    consecutive_count_0 = consecutive_mask_0.groupby((~consecutive_mask_0).cumsum()).cumsum()\n",
    "    mask_consecutive_0 = (consecutive_count_0 <= 24) | (~consecutive_mask_0)\n",
    "\n",
    "    combined_mask = mask_consecutive & mask_consecutive_0\n",
    "\n",
    "    filtered_data = data[combined_mask]\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def preprocessing_Y(df):\n",
    "    data = df.copy()\n",
    "    if 'time' in data.columns:\n",
    "        data.set_index('time', inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def add_estimated_flag(df, estimated):\n",
    "    data = df.copy()\n",
    "\n",
    "    data['estimated'] = 'E' if estimated else 'O'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/joakimness/Documents/GitHub/Solar-Energy-Production-Forecasting/data/short_notebook_1.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/joakimness/Documents/GitHub/Solar-Energy-Production-Forecasting/data/short_notebook_1.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scaler_a \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joakimness/Documents/GitHub/Solar-Energy-Production-Forecasting/data/short_notebook_1.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scaler_b \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joakimness/Documents/GitHub/Solar-Energy-Production-Forecasting/data/short_notebook_1.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scaler_c \u001b[39m=\u001b[39m MinMaxScaler()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "#combining observed and estimated data\n",
    "observed_a = preprocessing_X(X_train_observed_a)\n",
    "observed_a = add_estimated_flag(observed_a, False)\n",
    "\n",
    "estimated_a = preprocessing_X(X_train_estimated_a)\n",
    "estimated_a = add_estimated_flag(estimated_a, True)\n",
    "\n",
    "x_train_a = pd.concat([observed_a, estimated_a], axis=0)\n",
    "y_train_a = preprocessing_Y(train_a)\n",
    "m_train_a = x_train_a.merge(y_train_a, how='inner', on='time')\n",
    "\n",
    "observed_b = preprocessing_X(X_train_observed_b)\n",
    "observed_b = add_estimated_flag(observed_b, False)\n",
    "\n",
    "estimated_b = preprocessing_X(X_train_estimated_b)\n",
    "estimated_b = add_estimated_flag(estimated_b, True)\n",
    "\n",
    "x_train_b = pd.concat([observed_b, estimated_b], axis=0)\n",
    "y_train_b = preprocessing_Y(train_b)\n",
    "y_train_b = remove_constants_Y(y_train_b)\n",
    "m_train_b = x_train_b.merge(y_train_b, how='inner', on='time')\n",
    "\n",
    "observed_c = preprocessing_X(X_train_observed_c)\n",
    "observed_c = add_estimated_flag(observed_c, False)\n",
    "\n",
    "estimated_c = preprocessing_X(X_train_estimated_c)\n",
    "estimated_c = add_estimated_flag(estimated_c, True)\n",
    "\n",
    "x_train_c = pd.concat([observed_c, estimated_c], axis=0)\n",
    "y_train_c = preprocessing_Y(train_c)\n",
    "y_train_c = remove_constants_Y(y_train_c)\n",
    "m_train_c = x_train_c.merge(y_train_c, how='inner', on='time')\n",
    "\n",
    "x_train = pd.concat([m_train_a, m_train_b, m_train_c], axis=0, ignore_index=True)\n",
    "\n",
    "y_train = x_train['pv_measurement']\n",
    "\n",
    "x_train = x_train.drop(columns=['pv_measurement'], axis=1)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=10)\n",
    "\n",
    "X_train_a = X_train[X_train['location'] == 'A']\n",
    "X_train_b = X_train[X_train['location'] == 'B']\n",
    "X_train_c = X_train[X_train['location'] == 'C']\n",
    "\n",
    "Y_train_a = Y_train[X_train['location'] == 'A']\n",
    "Y_train_b = Y_train[X_train['location'] == 'B']\n",
    "Y_train_c = Y_train[X_train['location'] == 'C']\n",
    "\n",
    "X_val_a = X_val[X_val['location'] == 'A']\n",
    "X_val_b = X_val[X_val['location'] == 'B']\n",
    "X_val_c = X_val[X_val['location'] == 'C']\n",
    "\n",
    "Y_val_a = Y_val[X_val['location'] == 'A']\n",
    "Y_val_b = Y_val[X_val['location'] == 'B']\n",
    "Y_val_c = Y_val[X_val['location'] == 'C']\n",
    "\n",
    "x_test_a = preprocessing_X(X_test_estimated_a)\n",
    "x_test_a = add_estimated_flag(x_test_a, True)\n",
    "\n",
    "x_test_b = preprocessing_X(X_test_estimated_b)\n",
    "x_test_b = add_estimated_flag(x_test_b, True)\n",
    "\n",
    "x_test_c = preprocessing_X(X_test_estimated_c)\n",
    "x_test_c = add_estimated_flag(x_test_c, True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_test = pd.concat([x_test_a, x_test_b, x_test_c], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_190847/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_190847/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.18\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:22:05 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   630.56 GB / 994.66 GB (63.4%)\n",
      "Train Data Rows:    27220\n",
      "Train Data Columns: 49\n",
      "Tuning Data Rows:    6841\n",
      "Tuning Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 625.33327, 1156.81574)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6168.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.9 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['snow_drift:idx', 'location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('object', []) :  1 | ['estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t47 features in original data used to generate 47 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.85 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1755, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 931, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 946, in _predict_proba\n",
      "    y_pred = self.model.predict(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 236, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1755, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 931, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 946, in _predict_proba\n",
      "    y_pred = self.model.predict(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 239, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 170.153\n",
      "[2000]\tvalid_set's l1: 163.496\n",
      "[3000]\tvalid_set's l1: 160.526\n",
      "[4000]\tvalid_set's l1: 158.519\n",
      "[5000]\tvalid_set's l1: 157.406\n",
      "[6000]\tvalid_set's l1: 156.537\n",
      "[7000]\tvalid_set's l1: 155.928\n",
      "[8000]\tvalid_set's l1: 155.453\n",
      "[9000]\tvalid_set's l1: 155.163\n",
      "[10000]\tvalid_set's l1: 154.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-154.9279\t = Validation score   (-mean_absolute_error)\n",
      "\t34.47s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 171.235\n",
      "[2000]\tvalid_set's l1: 168.975\n",
      "[3000]\tvalid_set's l1: 167.793\n",
      "[4000]\tvalid_set's l1: 167.32\n",
      "[5000]\tvalid_set's l1: 167.111\n",
      "[6000]\tvalid_set's l1: 166.949\n",
      "[7000]\tvalid_set's l1: 166.833\n",
      "[8000]\tvalid_set's l1: 166.703\n",
      "[9000]\tvalid_set's l1: 166.666\n",
      "[10000]\tvalid_set's l1: 166.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-166.6311\t = Validation score   (-mean_absolute_error)\n",
      "\t27.47s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-184.8604\t = Validation score   (-mean_absolute_error)\n",
      "\t14.21s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-172.8182\t = Validation score   (-mean_absolute_error)\n",
      "\t92.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-184.0486\t = Validation score   (-mean_absolute_error)\n",
      "\t2.76s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-181.0095\t = Validation score   (-mean_absolute_error)\n",
      "\t19.0s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-177.6836\t = Validation score   (-mean_absolute_error)\n",
      "\t86.82s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-168.9959\t = Validation score   (-mean_absolute_error)\n",
      "\t30.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 165.067\n",
      "[2000]\tvalid_set's l1: 163.675\n",
      "[3000]\tvalid_set's l1: 163.349\n",
      "[4000]\tvalid_set's l1: 163.279\n",
      "[5000]\tvalid_set's l1: 163.255\n",
      "[6000]\tvalid_set's l1: 163.246\n",
      "[7000]\tvalid_set's l1: 163.24\n",
      "[8000]\tvalid_set's l1: 163.239\n",
      "[9000]\tvalid_set's l1: 163.238\n",
      "[10000]\tvalid_set's l1: 163.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-163.2376\t = Validation score   (-mean_absolute_error)\n",
      "\t96.31s\t = Training   runtime\n",
      "\t2.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-151.6939\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 411.4s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_190847/\")\n"
     ]
    }
   ],
   "source": [
    "X_train_a = X_train_a.copy()\n",
    "X_val_a = X_val_a.copy()\n",
    "\n",
    "X_train_a['pv_measurement'] = Y_train_a\n",
    "X_val_a['pv_measurement'] = Y_val_a\n",
    "predictor_a = TabularPredictor(\n",
    "                label='pv_measurement',\n",
    "                eval_metric='mean_absolute_error').fit(\n",
    "                    train_data=X_train_a,\n",
    "                    tuning_data=X_val_a\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_191539/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_191539/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.18\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:22:05 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   629.62 GB / 994.66 GB (63.3%)\n",
      "Train Data Rows:    21539\n",
      "Train Data Columns: 49\n",
      "Tuning Data Rows:    5311\n",
      "Tuning Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 103.28401, 209.28429)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5898.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.59 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('object', []) :  1 | ['estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 47 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t48 features in original data used to generate 48 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.5 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1755, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 931, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 946, in _predict_proba\n",
      "    y_pred = self.model.predict(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 236, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1755, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 931, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 946, in _predict_proba\n",
      "    y_pred = self.model.predict(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 239, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 24.2459\n",
      "[2000]\tvalid_set's l1: 23.4345\n",
      "[3000]\tvalid_set's l1: 23.0482\n",
      "[4000]\tvalid_set's l1: 22.8585\n",
      "[5000]\tvalid_set's l1: 22.6823\n",
      "[6000]\tvalid_set's l1: 22.5591\n",
      "[7000]\tvalid_set's l1: 22.4742\n",
      "[8000]\tvalid_set's l1: 22.3831\n",
      "[9000]\tvalid_set's l1: 22.3294\n",
      "[10000]\tvalid_set's l1: 22.2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-22.2833\t = Validation score   (-mean_absolute_error)\n",
      "\t26.31s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 25.2685\n",
      "[2000]\tvalid_set's l1: 24.9041\n",
      "[3000]\tvalid_set's l1: 24.7856\n",
      "[4000]\tvalid_set's l1: 24.7308\n",
      "[5000]\tvalid_set's l1: 24.7098\n",
      "[6000]\tvalid_set's l1: 24.6947\n",
      "[7000]\tvalid_set's l1: 24.6884\n",
      "[8000]\tvalid_set's l1: 24.6797\n",
      "[9000]\tvalid_set's l1: 24.675\n",
      "[10000]\tvalid_set's l1: 24.6724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-24.6724\t = Validation score   (-mean_absolute_error)\n",
      "\t25.47s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-27.3972\t = Validation score   (-mean_absolute_error)\n",
      "\t13.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-25.0711\t = Validation score   (-mean_absolute_error)\n",
      "\t89.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-27.2145\t = Validation score   (-mean_absolute_error)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-27.1468\t = Validation score   (-mean_absolute_error)\n",
      "\t11.98s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-25.6187\t = Validation score   (-mean_absolute_error)\n",
      "\t65.12s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-25.1312\t = Validation score   (-mean_absolute_error)\n",
      "\t23.38s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 24.2838\n",
      "[2000]\tvalid_set's l1: 24.1549\n",
      "[3000]\tvalid_set's l1: 24.1251\n",
      "[4000]\tvalid_set's l1: 24.1174\n",
      "[5000]\tvalid_set's l1: 24.1152\n",
      "[6000]\tvalid_set's l1: 24.1145\n",
      "[7000]\tvalid_set's l1: 24.1143\n",
      "[8000]\tvalid_set's l1: 24.1142\n",
      "[9000]\tvalid_set's l1: 24.1142\n",
      "[10000]\tvalid_set's l1: 24.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-24.1142\t = Validation score   (-mean_absolute_error)\n",
      "\t93.71s\t = Training   runtime\n",
      "\t1.92s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-21.9789\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 357.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_191539/\")\n"
     ]
    }
   ],
   "source": [
    "X_train_b = X_train_b.copy()\n",
    "X_val_b = X_val_b.copy()\n",
    "\n",
    "X_train_b['pv_measurement'] = Y_train_b\n",
    "X_val_b['pv_measurement'] = Y_val_b\n",
    "predictor_b = TabularPredictor(\n",
    "                label='pv_measurement',\n",
    "                eval_metric='mean_absolute_error').fit(\n",
    "                    train_data=X_train_b,\n",
    "                    tuning_data=X_val_b\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231109_192136/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231109_192136/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.18\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.6.0: Wed Jul  5 22:22:05 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   628.87 GB / 994.66 GB (63.2%)\n",
      "Train Data Rows:    17537\n",
      "Train Data Columns: 49\n",
      "Tuning Data Rows:    4422\n",
      "Tuning Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, 0.0, 91.46277, 176.08288)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5766.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.03 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['snow_drift:idx', 'location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('object', []) :  1 | ['estimated']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t47 features in original data used to generate 47 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.41 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Exception caused KNeighborsUnif to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1755, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 931, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 946, in _predict_proba\n",
      "    y_pred = self.model.predict(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 236, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Exception caused KNeighborsDist to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute 'split'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1755, in _train_and_save\n",
      "    y_pred_proba_val = model.predict_proba(X_val)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 931, in predict_proba\n",
      "    y_pred_proba = self._predict_proba(X=X, **kwargs)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 946, in _predict_proba\n",
      "    y_pred = self.model.predict(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_regression.py\", line 239, in predict\n",
      "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/neighbors/_base.py\", line 824, in kneighbors\n",
      "    results = ArgKmin.compute(\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\", line 289, in compute\n",
      "    return ArgKmin32.compute(\n",
      "  File \"sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\", line 584, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 139, in threadpool_limits\n",
      "    return threadpoolctl.threadpool_limits(limits=limits, user_api=user_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 171, in __init__\n",
      "    self._original_info = self._set_threadpool_limits()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 268, in _set_threadpool_limits\n",
      "    modules = _ThreadpoolInfo(prefixes=self._prefixes,\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 340, in __init__\n",
      "    self._load_modules()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 371, in _load_modules\n",
      "    self._find_modules_with_dyld()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 428, in _find_modules_with_dyld\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/Users/joakimness/anaconda3/envs/tdt4173/lib/python3.9/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 22.3454\n",
      "[2000]\tvalid_set's l1: 21.4621\n",
      "[3000]\tvalid_set's l1: 21.1152\n",
      "[4000]\tvalid_set's l1: 20.905\n",
      "[5000]\tvalid_set's l1: 20.7505\n",
      "[6000]\tvalid_set's l1: 20.6662\n",
      "[7000]\tvalid_set's l1: 20.6022\n",
      "[8000]\tvalid_set's l1: 20.5594\n",
      "[9000]\tvalid_set's l1: 20.5253\n",
      "[10000]\tvalid_set's l1: 20.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-20.5021\t = Validation score   (-mean_absolute_error)\n",
      "\t26.76s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 22.6198\n",
      "[2000]\tvalid_set's l1: 22.2574\n",
      "[3000]\tvalid_set's l1: 22.1781\n",
      "[4000]\tvalid_set's l1: 22.136\n",
      "[5000]\tvalid_set's l1: 22.1093\n",
      "[6000]\tvalid_set's l1: 22.0997\n",
      "[7000]\tvalid_set's l1: 22.0908\n",
      "[8000]\tvalid_set's l1: 22.0863\n",
      "[9000]\tvalid_set's l1: 22.084\n",
      "[10000]\tvalid_set's l1: 22.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-22.0821\t = Validation score   (-mean_absolute_error)\n",
      "\t22.9s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-24.8533\t = Validation score   (-mean_absolute_error)\n",
      "\t7.92s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-22.6419\t = Validation score   (-mean_absolute_error)\n",
      "\t87.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-24.4147\t = Validation score   (-mean_absolute_error)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-23.9851\t = Validation score   (-mean_absolute_error)\n",
      "\t9.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-23.2409\t = Validation score   (-mean_absolute_error)\n",
      "\t61.29s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-21.8483\t = Validation score   (-mean_absolute_error)\n",
      "\t28.79s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 22.0287\n",
      "[2000]\tvalid_set's l1: 21.9013\n",
      "[3000]\tvalid_set's l1: 21.8847\n",
      "[4000]\tvalid_set's l1: 21.8815\n",
      "[5000]\tvalid_set's l1: 21.881\n",
      "[6000]\tvalid_set's l1: 21.8809\n",
      "[7000]\tvalid_set's l1: 21.8809\n",
      "[8000]\tvalid_set's l1: 21.8809\n",
      "[9000]\tvalid_set's l1: 21.8809\n",
      "[10000]\tvalid_set's l1: 21.8809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-21.8809\t = Validation score   (-mean_absolute_error)\n",
      "\t84.94s\t = Training   runtime\n",
      "\t1.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-19.9105\t = Validation score   (-mean_absolute_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 336.1s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231109_192136/\")\n"
     ]
    }
   ],
   "source": [
    "X_train_c = X_train_c.copy()\n",
    "X_val_c = X_val_c.copy()\n",
    "\n",
    "X_train_c['pv_measurement'] = Y_train_c\n",
    "X_val_c['pv_measurement'] = Y_val_c\n",
    "predictor_c = TabularPredictor(\n",
    "                label='pv_measurement',\n",
    "                eval_metric='mean_absolute_error').fit(\n",
    "                    train_data=X_train_c,\n",
    "                    tuning_data=X_val_c\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2023-05-01 00:00:00   -1.074589\n",
       "2023-05-01 01:00:00   -1.661733\n",
       "2023-05-01 02:00:00   -1.057483\n",
       "2023-05-01 03:00:00   -1.326593\n",
       "2023-05-01 04:00:00   -1.053501\n",
       "Name: pv_measurement, dtype: float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_a = predictor_a.predict(x_test_a)\n",
    "y_pred_b = predictor_b.predict(x_test_b)\n",
    "y_pred_c = predictor_c.predict(x_test_c)\n",
    "\n",
    "y_pred_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-151.693877</td>\n",
       "      <td>-151.693877</td>\n",
       "      <td>3.742468</td>\n",
       "      <td>3.655949</td>\n",
       "      <td>188.590167</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.147905</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-154.927880</td>\n",
       "      <td>-154.927880</td>\n",
       "      <td>0.682783</td>\n",
       "      <td>0.768952</td>\n",
       "      <td>34.474560</td>\n",
       "      <td>0.682783</td>\n",
       "      <td>0.768952</td>\n",
       "      <td>34.474560</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-163.237628</td>\n",
       "      <td>-163.237628</td>\n",
       "      <td>2.196334</td>\n",
       "      <td>2.071631</td>\n",
       "      <td>96.312754</td>\n",
       "      <td>2.196334</td>\n",
       "      <td>2.071631</td>\n",
       "      <td>96.312754</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-166.631062</td>\n",
       "      <td>-166.631062</td>\n",
       "      <td>0.816492</td>\n",
       "      <td>0.787166</td>\n",
       "      <td>27.465005</td>\n",
       "      <td>0.816492</td>\n",
       "      <td>0.787166</td>\n",
       "      <td>27.465005</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-168.995947</td>\n",
       "      <td>-168.995947</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>30.189943</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.027411</td>\n",
       "      <td>30.189943</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-172.818230</td>\n",
       "      <td>-172.818230</td>\n",
       "      <td>0.052380</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>92.584997</td>\n",
       "      <td>0.052380</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>92.584997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-177.683620</td>\n",
       "      <td>-177.683620</td>\n",
       "      <td>0.897521</td>\n",
       "      <td>0.779569</td>\n",
       "      <td>86.821126</td>\n",
       "      <td>0.897521</td>\n",
       "      <td>0.779569</td>\n",
       "      <td>86.821126</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-181.009512</td>\n",
       "      <td>-181.009512</td>\n",
       "      <td>0.065075</td>\n",
       "      <td>0.046905</td>\n",
       "      <td>19.000463</td>\n",
       "      <td>0.065075</td>\n",
       "      <td>0.046905</td>\n",
       "      <td>19.000463</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-184.048648</td>\n",
       "      <td>-184.048648</td>\n",
       "      <td>0.218256</td>\n",
       "      <td>0.047898</td>\n",
       "      <td>2.762653</td>\n",
       "      <td>0.218256</td>\n",
       "      <td>0.047898</td>\n",
       "      <td>2.762653</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-184.860396</td>\n",
       "      <td>-184.860396</td>\n",
       "      <td>0.249706</td>\n",
       "      <td>0.045791</td>\n",
       "      <td>14.213299</td>\n",
       "      <td>0.249706</td>\n",
       "      <td>0.045791</td>\n",
       "      <td>14.213299</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test   score_val  pred_time_test  pred_time_val  \\\n",
       "0  WeightedEnsemble_L2 -151.693877 -151.693877        3.742468       3.655949   \n",
       "1           LightGBMXT -154.927880 -154.927880        0.682783       0.768952   \n",
       "2        LightGBMLarge -163.237628 -163.237628        2.196334       2.071631   \n",
       "3             LightGBM -166.631062 -166.631062        0.816492       0.787166   \n",
       "4       NeuralNetTorch -168.995947 -168.995947        0.037146       0.027411   \n",
       "5             CatBoost -172.818230 -172.818230        0.052380       0.014939   \n",
       "6              XGBoost -177.683620 -177.683620        0.897521       0.779569   \n",
       "7      NeuralNetFastAI -181.009512 -181.009512        0.065075       0.046905   \n",
       "8        ExtraTreesMSE -184.048648 -184.048648        0.218256       0.047898   \n",
       "9      RandomForestMSE -184.860396 -184.860396        0.249706       0.045791   \n",
       "\n",
       "     fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  188.590167                 0.009713                0.000789   \n",
       "1   34.474560                 0.682783                0.768952   \n",
       "2   96.312754                 2.196334                2.071631   \n",
       "3   27.465005                 0.816492                0.787166   \n",
       "4   30.189943                 0.037146                0.027411   \n",
       "5   92.584997                 0.052380                0.014939   \n",
       "6   86.821126                 0.897521                0.779569   \n",
       "7   19.000463                 0.065075                0.046905   \n",
       "8    2.762653                 0.218256                0.047898   \n",
       "9   14.213299                 0.249706                0.045791   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.147905            2       True         10  \n",
       "1          34.474560            1       True          1  \n",
       "2          96.312754            1       True          9  \n",
       "3          27.465005            1       True          2  \n",
       "4          30.189943            1       True          8  \n",
       "5          92.584997            1       True          4  \n",
       "6          86.821126            1       True          7  \n",
       "7          19.000463            1       True          6  \n",
       "8           2.762653            1       True          5  \n",
       "9          14.213299            1       True          3  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = predictor_a.evaluate(X_val_a, silent=True)\n",
    "predictor_a.leaderboard(X_val_a, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autogluon_predictions = pd.concat([y_pred_a, y_pred_b, y_pred_c], axis=0, ignore_index=True).to_frame()\n",
    "autogluon_predictions.index.name = 'id'\n",
    "autogluon_predictions.rename(columns={'pv_measurement': 'prediction'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from catboost import Pool\n",
    "\n",
    "params = {\n",
    "    'depth' : 9,\n",
    "    'iterations' : 1000,\n",
    "    'loss_function' : 'MAE'\n",
    "}\n",
    "\n",
    "def catboost(X_train, Y_train, X_val, Y_val):\n",
    "    \n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    train_pool = Pool(data=X_train, label=Y_train, cat_features=['location', 'estimated'])\n",
    "\n",
    "    eval_pool = Pool(data=X_val, label=Y_val, cat_features=['location', 'estimated'])\n",
    "\n",
    "    model.fit(train_pool, use_best_model=True, eval_set=eval_pool)\n",
    "    return model \n",
    "\n",
    "\n",
    "\n",
    "def train_predict(single=False):\n",
    "    lenlist = []\n",
    "    if not single:\n",
    "\n",
    "        model = catboost(X_train, Y_train, X_val, Y_val)\n",
    "        \n",
    "        predictions = pd.DataFrame(model.predict(x_test), columns=['prediction'])\n",
    "\n",
    "        predictions.index.name = 'id'\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    else:\n",
    "        model_a = catboost(X_train_a, Y_train_a, X_val_a, Y_val_a)\n",
    "        predict_a = model_a.predict(x_test_a)\n",
    "        predictions_a = pd.DataFrame(predict_a, columns=['prediction'])\n",
    "\n",
    "        model_b = catboost(X_train_b, Y_train_b, X_val_b, Y_val_b)\n",
    "        predict_b = model_b.predict(x_test_b)\n",
    "        predictions_b = pd.DataFrame(predict_b, columns=['prediction'])\n",
    "        \n",
    "        model_c = catboost(X_train_c, Y_train_c, X_val_c, Y_val_c)\n",
    "        predict_c = model_c.predict(x_test_c)\n",
    "        predictions_c = pd.DataFrame(predict_c, columns=['prediction'])\n",
    "\n",
    "        predictions = pd.concat([predictions_a, predictions_b, predictions_c], axis=0, ignore_index=True)\n",
    "\n",
    "        predictions.index.name = 'id'\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "def transformed_train_predict(single=False):\n",
    "    if not single:\n",
    "\n",
    "        model = catboost(transformed_X_train, transformed_Y_train, transformed_X_val, transformed_Y_val)\n",
    "        \n",
    "        predictions = pd.DataFrame(model.predict(x_test), columns=['prediction'])\n",
    "\n",
    "        predictions.index.name = 'id'\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    else:\n",
    "        model_a = catboost(transformed_X_train_a, transformed_Y_train_a, transformed_X_val_a, transformed_Y_val_a)\n",
    "        predict_a = model_a.predict(x_test_a)\n",
    "        predictions_a = pd.DataFrame(predict_a, columns=['prediction'])\n",
    "        predictions_a.loc[:, 'prediction'] = scaler_a.inverse_transform(predictions_a['prediction'].values.reshape(-1, 1))\n",
    "        \n",
    "\n",
    "        model_b = catboost(transformed_X_train_b, transformed_Y_train_b, transformed_X_val_b, transformed_Y_val_b)\n",
    "        predict_b = model_b.predict(x_test_b)\n",
    "        predictions_b = pd.DataFrame(predict_b, columns=['prediction'])\n",
    "        predictions_b.loc[:, 'prediction'] = scaler_b.inverse_transform(predictions_b['prediction'].values.reshape(-1, 1))\n",
    "\n",
    "        \n",
    "        model_c = catboost(transformed_X_train_c, transformed_Y_train_c, transformed_X_val_c, transformed_Y_val_c)\n",
    "        predict_c = model_c.predict(x_test_c)\n",
    "        predictions_c = pd.DataFrame(predict_c, columns=['prediction'])\n",
    "        predictions_c.loc[:, 'prediction'] = scaler_c.inverse_transform(predictions_c['prediction'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "        predictions = pd.concat([predictions_a, predictions_b, predictions_c], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "        predictions.index.name = 'id'\n",
    "        \n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating 100 different train_test splits\n",
    "for i in range(100):\n",
    "    \n",
    "    #creating datasets based on seed state i\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=i)\n",
    "\n",
    "    X_train_a = X_train[X_train['location'] == 'A']\n",
    "    X_train_b = X_train[X_train['location'] == 'B']\n",
    "    X_train_c = X_train[X_train['location'] == 'C']\n",
    "\n",
    "    Y_train_a = Y_train[X_train['location'] == 'A']\n",
    "    Y_train_b = Y_train[X_train['location'] == 'B']\n",
    "    Y_train_c = Y_train[X_train['location'] == 'C']\n",
    "\n",
    "    X_val_a = X_val[X_val['location'] == 'A']\n",
    "    X_val_b = X_val[X_val['location'] == 'B']\n",
    "    X_val_c = X_val[X_val['location'] == 'C']\n",
    "\n",
    "    Y_val_a = Y_val[X_val['location'] == 'A']\n",
    "    Y_val_b = Y_val[X_val['location'] == 'B']\n",
    "    Y_val_c = Y_val[X_val['location'] == 'C']\n",
    "\n",
    "\n",
    "    temp_catboost_prediction = train_predict(single=True)\n",
    "\n",
    "\n",
    "    #creating master dataframe\n",
    "    if i == 0:\n",
    "        catboost_master = pd.DataFrame()\n",
    "\n",
    "    #adding prediction to master dataframe\n",
    "    catboost_master[f'prediction_{i}'] = temp_catboost_prediction['prediction']\n",
    "        \n",
    "\n",
    "#establishing final dataframe\n",
    "catboost_predictions = pd.DataFrame()\n",
    "\n",
    "#calculating average for printout\n",
    "catboost_master['avg'] = catboost_master.mean(axis=1)\n",
    "\n",
    "#calculating mean\n",
    "catboost_predictions['prediction'] = catboost_master.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(features_df, preds_df):\n",
    "    features = features_df.copy()\n",
    "    preds = preds_df.copy()\n",
    "\n",
    "    # Set the index of 'features' to match 'preds'\n",
    "    features['is_day:idx'].index = preds.index\n",
    "\n",
    "    # Setting all night-time predictions to zero\n",
    "    preds.loc[features['is_day:idx'] == 0, 'prediction'] = 0\n",
    "\n",
    "    # Setting all low values to zero\n",
    "    preds['prediction'] = preds['prediction'].apply(lambda x: 0.0 if x < 1 else x)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_predictions_proc = postprocessing(x_test, catboost_predictions)\n",
    "autogluon_predictions_proc = postprocessing(x_test, autogluon_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "\n",
    "final['prediction'] =(\n",
    "                0.55 * catboost_predictions_proc['prediction'] + \n",
    "                0.45 * autogluon_predictions_proc['prediction']     \n",
    "                )            \n",
    "\n",
    "final.index.name = 'id'\n",
    "\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "\n",
    "final.to_csv(f'pred_{current_time}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
